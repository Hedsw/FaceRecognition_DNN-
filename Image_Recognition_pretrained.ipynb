{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image_Recognition_pretrained.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "mount_file_id": "1-mgwCHm7HB04tzBgsEn7vFirL5Uq1Wqy",
      "authorship_tag": "ABX9TyMJA4zAAK5APTzh+PhhF+Ug"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNojn-b_dqRk"
      },
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "from keras.applications import vgg16\n",
        "\n",
        "# Load Keras' VGG16 model that was pre-trained against the ImageNet database\n",
        "model = vgg16.VGG16()\n",
        "\n",
        "# Load the image file, resizing it to 224x224 pixels (required by this model)\n",
        "img = image.load_img(\"bay.jpg\", target_size=(224, 224))\n",
        "\n",
        "# Convert the image to a numpy array\n",
        "x = image.img_to_array(img)\n",
        "\n",
        "# Add a fourth dimension (since Keras expects a list of images)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "\n",
        "# Normalize the input image's pixel values to the range used when training the neural network\n",
        "x = vgg16.preprocess_input(x)\n",
        "\n",
        "# Run the image through the deep neural network to make a prediction\n",
        "predictions = model.predict(x)\n",
        "\n",
        "# Look up the names of the predicted classes. Index zero is the results for the first image.\n",
        "predicted_classes = vgg16.decode_predictions(predictions, top = 100)\n",
        "\n",
        "print(\"Top predictions for this image:\")\n",
        "\n",
        "for imagenet_id, name, likelihood in predicted_classes[0]:\n",
        "    print(\"Prediction: {} - {:2f}\".format(name, likelihood))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBKK4yOVfiuX"
      },
      "source": [
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import joblib\n",
        "from keras.preprocessing import image\n",
        "from keras.applications import vgg16\n",
        "\n",
        "# Path to folders with training data\n",
        "dog_path = Path(\"/content/drive/My Drive/Colab_Notebooks/data/training_data\") / \"dogs\"\n",
        "not_dog_path = Path(\"/content/drive/My Drive/Colab_Notebooks/data/training_data\") / \"not_dogs\"\n",
        "\n",
        "images = []\n",
        "labels = []\n",
        "\n",
        "# Load all the not-dog images\n",
        "for img in not_dog_path.glob(\"*.png\"):\n",
        "    # Load the image from disk\n",
        "    img = image.load_img(img)\n",
        "\n",
        "    # Convert the image to a numpy array\n",
        "    image_array = image.img_to_array(img)\n",
        "\n",
        "    # Add the image to the list of images\n",
        "    images.append(image_array)\n",
        "\n",
        "    # For each 'not dog' image, the expected value should be 0\n",
        "    labels.append(0)\n",
        "\n",
        "# Load all the dog images\n",
        "for img in dog_path.glob(\"*.png\"):\n",
        "    # Load the image from disk\n",
        "    img = image.load_img(img)\n",
        "\n",
        "    # Convert the image to a numpy array\n",
        "    image_array = image.img_to_array(img)\n",
        "\n",
        "    # Add the image to the list of images\n",
        "    images.append(image_array)\n",
        "\n",
        "    # For each 'dog' image, the expected value should be 1\n",
        "    labels.append(1)\n",
        "\n",
        "# Create a single numpy array with all the images we loaded\n",
        "x_train = np.array(images)\n",
        "\n",
        "# Also convert the labels to a numpy array\n",
        "y_train = np.array(labels)\n",
        "\n",
        "# Normalize image data to 0-to-1 range\n",
        "x_train = vgg16.preprocess_input(x_train)\n",
        "\n",
        "# Load a pre-trained neural network to use as a feature extractor\n",
        "pretrained_nn = vgg16.VGG16(weights = \"imagenet\", include_top = False, input_shape=(64, 64, 3))\n",
        "\n",
        "# Extract features for each image (all in one pass)\n",
        "features_x = pretrained_nn.predict(x_train)\n",
        "\n",
        "# Save the array of extracted features to a file\n",
        "joblib.dump(features_x, \"x_train.dat\")\n",
        "\n",
        "# Save the matching array of expected values to a file\n",
        "joblib.dump(y_train, \"y_train.dat\")\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}